<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.3">Jekyll</generator><link href="https://tsairesearch.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://tsairesearch.github.io/" rel="alternate" type="text/html" /><updated>2019-11-06T10:46:59-06:00</updated><id>https://tsairesearch.github.io/</id><title type="html">The Scientific AI Research Group</title><entry><title type="html">Sampling and Classification of Point Clouds</title><link href="https://tsairesearch.github.io/projects/rays" rel="alternate" type="text/html" title="Sampling and Classification of Point Clouds" /><published>2019-11-06T00:00:00-06:00</published><updated>2019-11-06T00:00:00-06:00</updated><id>https://tsairesearch.github.io/projects/rays</id><content type="html" xml:base="https://tsairesearch.github.io/projects/rays">&lt;d-front-matter&gt;
  &lt;script type=&quot;text/json&quot;&gt;{
  &quot;authors&quot;: [
    {
      &quot;author&quot;: &quot;Lewis Liu&quot;,
      &quot;authorURL&quot;: &quot;https://www.iam.ubc.ca/liangchen-liu/&quot;,
      &quot;affiliation&quot;: &quot;Department of Mathematics, The University of British Columbia&quot;,
      &quot;affiliationURL&quot;: &quot;https://ubc.ca&quot;
    },
    {
      &quot;author&quot;: &quot;Louis Ly&quot;,
      &quot;authorURL&quot;: &quot;https://longlouisly.github.io/&quot;,
      &quot;affiliation&quot;: &quot;Oden Institute for Computational Engineering and Sciences, The University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.ices.utexas.edu&quot;
    },
    {
      &quot;author&quot;: &quot;Colin Macdonald&quot;,
      &quot;authorURL&quot;: &quot;https://www.math.ubc.ca/~cbm/&quot;,
      &quot;affiliation&quot;: &quot;Department of Mathematics, The University of British Columbia&quot;,
      &quot;affiliationURL&quot;: &quot;https://ubc.ca&quot;
    },

    {
      &quot;author&quot;: &quot;Yen-Hsi Richard Tsai&quot;,
      &quot;authorURL&quot;: &quot;https://www.ma.utexas.edu/users/ytsai/&quot;,
      &quot;affiliation&quot;: &quot;Oden Institute for Computational Engineering and Sciences, The University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.oden.utexas.edu&quot;
    }
  ]
  }&lt;/script&gt;
&lt;/d-front-matter&gt;

&lt;d-title&gt;
 &lt;div style=&quot;grid-column: screen; text-align: center&quot;&gt;
  &lt;h1&gt;Sampling and Classification of Point Clouds&lt;/h1&gt;
    
    &lt;img style=&quot;display: block; max-width: 15%; margin-top: 3rem; margin-bottom: 3rem; margin-left: auto; margin-right: auto; border-radius: 5%&quot; alt=&quot;Sampling and Classification of Point Clouds&quot; src=&quot;https://tsairesearch.github.io//assets/images/rays/airplane_ray.png&quot; /&gt;
    
 &lt;/div&gt;


&lt;/d-title&gt;

&lt;d-article&gt;

&lt;p&gt; We propose a new framework for the sampling, compression, and analysis of
distributions of point sets embedded in Euclidean spaces. A set of randomly
selected rays are projected onto their closest points in the data set and thus
form the signature of the data set. From the signature, statistical
information about the data set, as well as certain geometrical information can
be extracted, independent of the ray set. We show that the cost of the sampling
approach is asymptotically independent of the ray sets.  Finally, we present a
neural network model using the  signature for classification of point
sets in three dimensions. &lt;/p&gt;

&lt;h3&gt; Examples &lt;/h3&gt;


&lt;div style=&quot;grid-column: screen &quot;&gt;

&lt;figure&gt;
&lt;div style=&quot;display: block; width: 100%; text-align: center&quot;&gt;
&lt;iframe width=&quot;1296px&quot; height=&quot;850px&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot; src=&quot;https://tsairesearch.github.io/assets/images/rays/grid.png&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;figcaption&gt;
&lt;div style=&quot;display: block; margin-right: auto; margin-left: auto; width: 50%; text-align: center&quot;&gt;
(Row 1) Visualization of a two rays (black) through points sampled from various objects (gray). Closest point pairs are shown in green and red. (Row 2) Plot of distance from points along the ray to the corresponding closest points on the object. (Rows 3-5) The $x$, $y$, and $z$ coordinates of the closest points to the ray.
&lt;/div&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;div style=&quot;grid-column: screen &quot;&gt;

&lt;figure&gt;
&lt;div style=&quot;display: block; width: 100%; text-align: center&quot;&gt;
&lt;iframe width=&quot;1000px&quot; height=&quot;500px&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot; src=&quot;https://tsairesearch.github.io/assets/images/rays/airplane_side.png&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;figcaption&gt;
&lt;div style=&quot;display: block; margin-right: auto; margin-left: auto; width: 50%; text-align: center&quot;&gt;
Rays are more likely to sample salient features in the point cloud. Larger points are repeated more often.
We can control the number of points by increasing the number of rays. Each ray contains 30 sample points.  
&lt;/div&gt;
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;



&lt;h3&gt; Classification using Deep Neural Networks &lt;/h3&gt;


&lt;div style=&quot;grid-column: screen; margin-left: auto; margin-right: auto; text-align: center &quot;&gt;

&lt;div style=&quot;display: block; margin-right: auto; margin-left: auto; width: 80%; text-align: center&quot;&gt;
&lt;figure&gt;
&lt;figcaption&gt;
&lt;div style=&quot;display: block; margin-right: auto; margin-left: auto; width: 100%; text-align: center&quot;&gt;
Comparison of our deep neural network model against PointNet on ModelNet point cloud classification dataset.
&lt;/div&gt;
&lt;/figcaption&gt;


&lt;table&gt;
  &lt;tr&gt;
    &lt;th class=&quot;tg-0pky&quot;&gt;Model&lt;/th&gt;
    &lt;th class=&quot;tg-0pky&quot;&gt;ModelNet10 (2048)&lt;/th&gt;
    &lt;th class=&quot;tg-0pky&quot;&gt;ModelNet40 (2048)&lt;/th&gt;
    &lt;th class=&quot;tg-0pky&quot;&gt;ModelNet40 (1024)&lt;/th&gt;
    &lt;th class=&quot;tg-0pky&quot;&gt;ModelNet40 (4096)&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;PointNet (paper)&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;-&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;-&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;89.2%&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;-&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;PointNet.pytorch&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;92.07% (on 256 pts)&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;85.3% (on 1024 pts)&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;87.52%&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;85.4%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;Ours&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;95.04%&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;90.03%&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;90.6%&lt;/td&gt;
    &lt;td class=&quot;tg-0pky&quot;&gt;90.44%&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;/figure&gt;
&lt;/div&gt;

&lt;div style=&quot;display: block; margin-right: auto; margin-left: auto; width: 50%; text-align: center&quot;&gt;
&lt;figure&gt;
&lt;figcaption&gt;
&lt;div style=&quot;display: block; margin-right: auto; margin-left: auto; width: 100%; text-align: center&quot;&gt;
Sensitivity of the neural network models to the input size. Here, $m$ is the number of rays, $N^\ast$ is the number of points used, and $N$ is the total number of points in the original point set.
&lt;/div&gt;
&lt;/figcaption&gt;


&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Our model on ModelNet10 (N=2048)&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;$m/32$&lt;/td&gt;
    &lt;td&gt;100%&lt;/td&gt;
    &lt;td&gt;50%&lt;/td&gt;
    &lt;td&gt;25%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;$N^\ast/N$&lt;/td&gt;
    &lt;td&gt;15.38%&lt;/td&gt;
    &lt;td&gt;8.59%&lt;/td&gt;
    &lt;td&gt;4.59%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Performance/Accuracy&lt;/td&gt;
    &lt;td&gt;94.60%&lt;/td&gt;
    &lt;td&gt;95.04%&lt;/td&gt;
    &lt;td&gt;94.60%&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;


&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Our model on ModelNet40 (N=1024)&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;$m/32$&lt;/td&gt;
    &lt;td&gt;100%&lt;/td&gt;
    &lt;td&gt;50%&lt;/td&gt;
    &lt;td&gt;25%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;$N^\ast/N$&lt;/td&gt;
    &lt;td&gt;25.10%&lt;/td&gt;
    &lt;td&gt;14.75%&lt;/td&gt;
    &lt;td&gt;8.17%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Performance/Accuracy&lt;/td&gt;
    &lt;td&gt;90.56%&lt;/td&gt;
    &lt;td&gt;90.60%&lt;/td&gt;
    &lt;td&gt;89.82%&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;PointNet on ModelNet40 (N=1024)&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;$N^\ast/N$&lt;/td&gt;
    &lt;td&gt;100%&lt;/td&gt;
    &lt;td&gt;50%&lt;/td&gt;
    &lt;td&gt;12.5%&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Performance/Accuracy&lt;/td&gt;
    &lt;td&gt;89.2%&lt;/td&gt;
    &lt;td&gt;86.8%&lt;/td&gt;
    &lt;td&gt;69%&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;/div&gt;


&lt;/d-article&gt;</content><author><name></name></author><category term="projects" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tsairesearch.github.io/assets/images/rays/airplane_ray.png" /></entry><entry><title type="html">Mathematics in Deep Learning —Syllabus</title><link href="https://tsairesearch.github.io/notes/syllabus" rel="alternate" type="text/html" title="Mathematics in Deep Learning ---Syllabus" /><published>2019-10-20T00:00:00-05:00</published><updated>2019-10-20T00:00:00-05:00</updated><id>https://tsairesearch.github.io/notes/syllabus</id><content type="html" xml:base="https://tsairesearch.github.io/notes/syllabus">&lt;p&gt;Welcome to the zoo!&lt;/p&gt;

&lt;p&gt;A tentative list of topics to be covered in this course.&lt;/p&gt;

&lt;p&gt;The course will be conducted with a mixture of regular lectures, seminar style presentation and discussion.&lt;/p&gt;

&lt;p&gt;Participants of this course are expected to present certain relevant concepts from suggested reading assignments, and arrange the presentation in a certain uniform style.&lt;/p&gt;

&lt;h3 id=&quot;deep-learning-architectures-and-the-related-applications&quot;&gt;Deep learning architectures and the related applications:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;basic multi-layer neural networks (NNs)&lt;/li&gt;
  &lt;li&gt;convolutional Neural networks (CNNs)&lt;/li&gt;
  &lt;li&gt;residual neural networks (ResNets)&lt;/li&gt;
  &lt;li&gt;generative adversarial networks (GANs) and the Wasserstein GANs&lt;/li&gt;
  &lt;li&gt;recurrent neural network (RNN)&lt;/li&gt;
  &lt;li&gt;LSTMs&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;convolutional Neural networks for graphs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;encoder-decoders&lt;/li&gt;
  &lt;li&gt;reinforcement learning (value iteration, policy iteration)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;algorithmic-components&quot;&gt;Algorithmic components:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;stochastic gradient descent algorithms&lt;/li&gt;
  &lt;li&gt;backpropagation and automatic differentiation&lt;/li&gt;
  &lt;li&gt;computational graphs&lt;/li&gt;
  &lt;li&gt;search algorithms: Monte-Carlo Tree Search used in AlphaGo&lt;/li&gt;
  &lt;li&gt;classical multi-level algorithms: multigrid methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;approximation-theory&quot;&gt;Approximation theory:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;classical multi-resolution analysis (wavelet)&lt;/li&gt;
  &lt;li&gt;compressive sensing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The curse of dimensionality!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;single layer universal approximation theory&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;multi-layer neural network approximation theory&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;over-parameterization and generalization&lt;/li&gt;
  &lt;li&gt;linear algebra: defining notions of distances from data matrices&lt;/li&gt;
  &lt;li&gt;manifold learning&lt;/li&gt;
  &lt;li&gt;transfer learning&lt;/li&gt;
  &lt;li&gt;adversarial attacks&lt;/li&gt;
  &lt;li&gt;differential privacy&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;random-graphs-and-random-matrices&quot;&gt;Random graphs and random matrices:&lt;/h3&gt;

&lt;h3 id=&quot;optimization-algorithms-and-theories&quot;&gt;Optimization algorithms and theories:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;efficient algorithms for finding a/the minimum of a loss function&lt;/li&gt;
  &lt;li&gt;mini-batch and minimizing variances&lt;/li&gt;
  &lt;li&gt;duality, saddle point problems&lt;/li&gt;
  &lt;li&gt;primal-dual type splitting algorithms&lt;/li&gt;
  &lt;li&gt;Nesterov’s algorithm&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;how to select your mini-batches?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;which loss function?&lt;/li&gt;
  &lt;li&gt;the vanishing gradient problem of using &lt;em&gt;Sigmoids&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;cross-entropy&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dynamical-system&quot;&gt;Dynamical system:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;stability&lt;/li&gt;
  &lt;li&gt;automatic step size control&lt;/li&gt;
  &lt;li&gt;optimal control of dynamical systems&lt;/li&gt;
  &lt;li&gt;Decoupling algorithms&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;optimal-transport-theory-and-algorithms&quot;&gt;Optimal transport theory and algorithms:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Comparing probability densities&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Earth mover’s distances “convexify”&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;The Benamou-Brenier fluid formulation and related algorithms&lt;/li&gt;
  &lt;li&gt;Sinkhorn algorithm&lt;/li&gt;
  &lt;li&gt;Information Geometry&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;some-novel-applications&quot;&gt;Some novel applications:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Beyond image processing and facial recognition&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;deep-learning-for-scientific-computing&quot;&gt;Deep learning for scientific computing:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;wave propagation&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Louis and Richard</name></author><category term="notes" /><summary type="html">Welcome to the zoo!</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tsairesearch.github.io/assets/images/github_avatar.jpg" /></entry><entry><title type="html">Multiscale coupling algorithms using parareal style structures</title><link href="https://tsairesearch.github.io/projects/parareal" rel="alternate" type="text/html" title="Multiscale coupling algorithms using parareal style structures" /><published>2019-10-04T00:00:00-05:00</published><updated>2019-10-04T00:00:00-05:00</updated><id>https://tsairesearch.github.io/projects/parareal</id><content type="html" xml:base="https://tsairesearch.github.io/projects/parareal">&lt;d-front-matter&gt;
  &lt;script type=&quot;text/json&quot;&gt;{
  &quot;authors&quot;: [
    {
      &quot;author&quot;: &quot;Hieu Nguyen&quot;,
      &quot;authorURL&quot;: &quot;https://www.oden.utexas.edu/&quot;,
      &quot;affiliation&quot;: &quot;Oden Institute for Computational Engineering and Sciences, University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.oden.utexas.edu&quot;
    },
    {
      &quot;author&quot;: &quot;Yen-Hsi Richard Tsai&quot;,
      &quot;authorURL&quot;: &quot;https://www.ma.utexas.edu/users/ytsai/&quot;,
      &quot;affiliation&quot;: &quot;Oden Institute for Computational Engineering and Sciences, University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.oden.utexas.edu&quot;
    }
  ]
  }&lt;/script&gt;
&lt;/d-front-matter&gt;

&lt;d-title&gt;
 &lt;div style=&quot;grid-column: screen; text-align: center&quot;&gt;
  &lt;h1&gt;Multiscale coupling algorithms using parareal style structures&lt;/h1&gt;
    
    &lt;img style=&quot;display: block; max-width: 15%; margin-top: 3rem; margin-bottom: 3rem; margin-left: auto; margin-right: auto; border-radius: 5%&quot; alt=&quot;Multiscale coupling algorithms using parareal style structures&quot; src=&quot;https://tsairesearch.github.io//assets/images/wave/waveinmarmousi.gif&quot; /&gt;
    
 &lt;/div&gt;


&lt;/d-title&gt;

&lt;d-article&gt;

&lt;p&gt;We are developing a data-driven parallel-in-time iterative method to solve the homogeneous second-order wave equation. The new method involves a coarse-scale propagator and a fine-scale propagator which fully resolves the medium using finer spatial grid and shorter time steps. The fine-scale propagator is run in parallel for short time subintervals. The two propagators are coupled in an iterative way similar to the standard parareal method. We train a Neural Network, which structure mimics the physics of wave propagation, to enhance the accuracy of the coarse-scale propagator such that the parareal iteration stabilizes and hence converges.&lt;/p&gt;

&lt;h3&gt; Simulation &lt;/h3&gt;


&lt;div style=&quot;column-grid: middle &quot;&gt;

&lt;figure&gt;
&lt;div style=&quot;display: block; width: 90%; text-align: center&quot;&gt;
&lt;iframe width=&quot;547px&quot; height=&quot;547px&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot; src=&quot;https://tsairesearch.github.io/assets/images/wave/waveinmarmousi.gif&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;figcaption&gt;
Wave propagating through Marmousi velocity profile.
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;/div&gt;


&lt;h3&gt; Publications &lt;/h3&gt;

&lt;p&gt;
&lt;li&gt; G. Ariel, H. Nguyen, and R. Tsai. &quot;\theta-parareal schemes.&quot; arXiv preprint arXiv:1704.06882 (2017). &lt;/li&gt;
&lt;li&gt; H. Nguyen, and R. Tsai. &quot;A stable parareal-like method for the second order wave equation.&quot; arXiv preprint arXiv:1905.00473 (2019).&lt;/li&gt;
&lt;/p&gt;



&lt;/d-article&gt;</content><author><name></name></author><category term="projects" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tsairesearch.github.io/assets/images/wave/waveinmarmousi.gif" /></entry><entry><title type="html">Strategy Synthesis for Surveillance-Evasion Games with Learning-enabled Visibility Optimization</title><link href="https://tsairesearch.github.io/projects/evasion" rel="alternate" type="text/html" title="Strategy Synthesis for Surveillance-Evasion Games with Learning-enabled Visibility Optimization" /><published>2019-03-20T00:00:00-05:00</published><updated>2019-03-20T00:00:00-05:00</updated><id>https://tsairesearch.github.io/projects/evasion</id><content type="html" xml:base="https://tsairesearch.github.io/projects/evasion">&lt;d-front-matter&gt;
  &lt;script type=&quot;text/json&quot;&gt;{
  &quot;authors&quot;: [
    {
      &quot;author&quot;: &quot;Suda Bharadwaj&quot;,
      &quot;authorURL&quot;: &quot;https://www.linkedin.com/in/suda-bharadwaj-23784137&quot;,
      &quot;affiliation&quot;: &quot;Aerospace Engineering &amp; Engineering Mechanics, The University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.robotics.utexas.edu&quot;
    },
    {
      &quot;author&quot;: &quot;Louis Ly&quot;,
      &quot;authorURL&quot;: &quot;https://longlouisly.github.io/&quot;,
      &quot;affiliation&quot;: &quot;Institute for Computational Engineering and Sciences, The University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.oden.utexas.edu&quot;
    },
    {
      &quot;author&quot;: &quot;Bo Wu&quot;,
      &quot;authorURL&quot;: &quot;https://users.oden.utexas.edu/~bwu/&quot;,
      &quot;affiliation&quot;: &quot;Institute for Computational Engineering and Sciences, The University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.oden.utexas.edu&quot;
    },
    {
      &quot;author&quot;: &quot;Yen-Hsi Richard Tsai&quot;,
      &quot;authorURL&quot;: &quot;https://www.ma.utexas.edu/users/ytsai/&quot;,
      &quot;affiliation&quot;: &quot;Institute for Computational Engineering and Sciences, The University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.oden.utexas.edu&quot;
    },
    {
      &quot;author&quot;: &quot;Ufuk Topcu&quot;,
      &quot;authorURL&quot;: &quot;https://www.ae.utexas.edu/facultysites/topcu/wiki/index.php/Main_Page&quot;,
      &quot;affiliation&quot;: &quot;Aerospace Engineering and Engineering Mechanics, The University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.oden.utexas.edu&quot;
    }
  ]
  }&lt;/script&gt;
&lt;/d-front-matter&gt;

&lt;d-title&gt;
 &lt;div style=&quot;grid-column: screen; text-align: center&quot;&gt;
  &lt;h1&gt;Strategy Synthesis for Surveillance-Evasion Games with Learning-enabled Visibility Optimization&lt;/h1&gt;
    
    &lt;img style=&quot;display: block; max-width: 15%; margin-top: 3rem; margin-bottom: 3rem; margin-left: auto; margin-right: auto; border-radius: 5%&quot; alt=&quot;Strategy Synthesis for Surveillance-Evasion Games with Learning-enabled Visibility Optimization&quot; src=&quot;https://tsairesearch.github.io//assets/images/evasion/patrol.gif&quot; /&gt;
    
 &lt;/div&gt;


&lt;/d-title&gt;

&lt;d-article&gt;

&lt;p&gt;We study a two-player game with a quantitative surveillance requirement on an
adversarial target moving in a discrete state space and a secondary objective
to maximize short-term visibility of the environment. We impose the
surveillance requirement as a temporal logic constraint. We then use a greedy
approach to determine vantage points that optimize a notion of information
gain, namely, the number of newly-seen states. By using a convolutional neural
network trained on a class of environments, we can efficiently approximate
the information gain at each potential vantage point. Subsequent vantage points
are chosen such that moving to that location will not jeopardize the
surveillance requirement, regardless of any future action chosen by the
target. Our method combines guarantees of correctness from formal methods with
the scalability of machine learning to provide an efficient approach for
surveillance-constrained visibility optimization.&lt;/p&gt;

&lt;h3&gt; Simulations &lt;/h3&gt;


&lt;div style=&quot;grid-column: text;&quot;&gt;

&lt;figure&gt;
&lt;div style=&quot;display: inline; float: left; width: 50%; text-align: center&quot;&gt;
&lt;iframe frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot; src=&quot;https://drive.google.com/file/d/1Is8AIsAQB5zL1iCdtaKLMpL33oYpqV99/preview&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;div style=&quot;display: inline; float: left; width: 50%; text-align: center&quot;&gt;
&lt;iframe frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot; src=&quot;https://drive.google.com/file/d/1Ppf2gh0pmyD7lAZO9WCxh04ln7RaUEtX/preview&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;figcaption&gt;
We present videos demonstrating the agent's strategies synthesized by our
algorithm.  The blue circle corresponds to the controlled agent and the orange
circle corresponds to the hostile target.  Red cells are obstacles that cannot
be passed through and obscure vision. Black cells correspond to states
the agent cannot see.

The video on the left shows an agent with the surveillance
objective: always mantain visibility of the target. Notice the agent tends to stay still until it is necessary to move.
On the right video, the agent must also patrol the environment, in addition to the surveillance requirement.
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;/div&gt;


&lt;h3&gt; Publications &lt;/h3&gt;

&lt;p&gt;
&lt;li&gt; Suda Bharadwaj, Louis Ly, Bo Wu, Richard Tsai, and Ufuk Topcu. &quot;Strategy synthesis for surveillance-evasion games with learning-enabled visibility optimization.&quot; 2019 Conference on Decision and Control (CDC). IEEE, 2019. &lt;/li&gt;
&lt;/p&gt;



&lt;/d-article&gt;</content><author><name></name></author><category term="projects" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tsairesearch.github.io/assets/images/evasion/patrol.gif" /></entry><entry><title type="html">AI-enabled Exploration and Surveillance</title><link href="https://tsairesearch.github.io/projects/autonomous" rel="alternate" type="text/html" title="AI-enabled Exploration and Surveillance" /><published>2018-06-15T00:00:00-05:00</published><updated>2018-06-15T00:00:00-05:00</updated><id>https://tsairesearch.github.io/projects/autonomous</id><content type="html" xml:base="https://tsairesearch.github.io/projects/autonomous">&lt;d-front-matter&gt;
  &lt;script type=&quot;text/json&quot;&gt;{
  &quot;authors&quot;: [
    {
      &quot;author&quot;: &quot;Louis Ly&quot;,
      &quot;authorURL&quot;: &quot;https://longlouisly.github.io/&quot;,
      &quot;affiliation&quot;: &quot;Institute for Computational Engineering and Sciences, University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.ices.utexas.edu&quot;
    },
    {
      &quot;author&quot;: &quot;Yen-Hsi Richard Tsai&quot;,
      &quot;authorURL&quot;: &quot;https://www.ma.utexas.edu/users/ytsai/&quot;,
      &quot;affiliation&quot;: &quot;Institute for Computational Engineering and Sciences, University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.ices.utexas.edu&quot;
    }
  ]
  }&lt;/script&gt;
&lt;/d-front-matter&gt;

&lt;d-title&gt;
 &lt;div style=&quot;grid-column: screen; text-align: center&quot;&gt;
  &lt;h1&gt;AI-enabled Exploration and Surveillance&lt;/h1&gt;
    
    &lt;img style=&quot;display: block; max-width: 15%; margin-top: 3rem; margin-bottom: 3rem; margin-left: auto; margin-right: auto; border-radius: 5%&quot; alt=&quot;AI-enabled Exploration and Surveillance&quot; src=&quot;https://tsairesearch.github.io//assets/images/autonomous/3d.gif&quot; /&gt;
    
 &lt;/div&gt;


&lt;/d-title&gt;

&lt;d-article&gt;

&lt;p&gt;We develop a new state-of-the-art deep learning strategy for prescribing vantage points for optimal sensor placement. This approach uses a robust volumetric visibility computation to efficiently model arbitrary geometries. We present several simulations on urban environments below.&lt;/p&gt;

&lt;h3&gt; 2D Urban Simulations &lt;/h3&gt;


&lt;div style=&quot;grid-column: text;&quot;&gt;

&lt;figure&gt;
&lt;div style=&quot;display: inline; float: left; width: 50%; text-align: center&quot;&gt;
&lt;iframe frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot; src=&quot;https://drive.google.com/file/d/1-dvc6IDh0ItwHaS78-vBv2u5VY8ojRmb/preview&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;div style=&quot;display: inline; float: left; width: 50%; text-align: center&quot;&gt;
&lt;iframe frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot; src=&quot;https://drive.google.com/file/d/1hm9AromseSBybcNxtV7DK-pWTb_gcCeW/preview&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;figcaption&gt;
A demonstration of two different policies for generating vantage points using deep learning, set over an aerial view of a 150m x 150m area in Austin. The agent starts in an initially unknown environment. At prescribed vantage point, it takes an omni-directional sensor measurement encoding line-of-sight information. Red dot indicates current position. Blue disks are previous vantage points. White regions are visible at the current positon. Light gray regions were visible at previous vantage points. Dark gray regions are currently occluded. Black lines indicate boundaries of reconstructed buildings.
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;/div&gt;

&lt;h3&gt; 3D Urban Simulations &lt;/h3&gt;

A 3D simulation of a 250m x 250m environment based on Castle Square Parks in Boston.

&lt;div style=&quot;column-grid: middle &quot;&gt;
&lt;figure&gt;
&lt;div style=&quot;text-align: center&quot;&gt;
&lt;iframe width=&quot;720px&quot; height=&quot;480px&quot; allowfullscreen=&quot;true&quot; src=&quot;https://drive.google.com/file/d/15_xI-qUFzMb8ydbnPq2CrZ2CNEa0Fab7/preview&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;
 &lt;figcaption&gt;
   Video demonstrating the exploration of an initially unknown environment using sparse sensor measurements. The green spheres indicate the vantage point. The gray surface is the reconstruction of the environment based on line of sight measurements taken from the sequence of vantage points. New vantage points are computed in virtually real time using our new deep learning strategy. Best viewed in full screen. 
 &lt;/figcaption&gt;
&lt;/figure&gt;



&lt;figure&gt;
&lt;img style=&quot;display: block; max-width: 100%; margin-top: 3rem; margin-bottom: 1rem; margin-left: auto; margin-right: auto&quot; alt=&quot;AI-enabled Exploration and Surveillance&quot; src=&quot;https://tsairesearch.github.io/assets/images/autonomous/sight1.jpg&quot; /&gt;
&lt;figcaption&gt;
Surveillance of urban environment using 2 sensors represented by green spheres. Yellow regions are visible from one of the sensors. Red regions are visible from both sensors. For clarity, visualization only includes visibility of regions near ground level. Two sample paths across the courtyard are shown. The cyan path uses the shadows of structure to minimize detection while the magenta path naively crosses through.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;h3&gt; 3D MOUT Site &lt;/h3&gt;

Realistic LiDAR simulations of a virtual Military Operations in Urban Terrain (MOUT) site. Vantage points are generated using a previous approach.


&lt;div style=&quot;grid-column: text;&quot;&gt;

&lt;div style=&quot;display: inline; float: left; width: 45%; text-align: center&quot;&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; max-width: 100%; margin-top: 3rem; margin-bottom: 1rem; margin-left: auto; margin-right: auto&quot; alt=&quot;AI-enabled Exploration and Surveillance&quot; src=&quot;https://tsairesearch.github.io/assets/images/autonomous/mout1_textured.jpg&quot; /&gt;
&lt;figcaption&gt;
A 20m region around a patio area with tree cover from the virtual MOUT site.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;div style=&quot;display: inline; float: right; width: 45%; text-align: center&quot;&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; max-width: 100%; margin-top: 3rem; margin-bottom: 1rem; margin-left: auto; margin-right: auto&quot; alt=&quot;AI-enabled Exploration and Surveillance&quot; src=&quot;https://tsairesearch.github.io/assets/images/autonomous/mout1_points.jpg&quot; /&gt;
&lt;figcaption&gt;
The integrated visibility volume of the patio area generated from 16 vantage points, shown as red circles.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;/div&gt;


&lt;div style=&quot;grid-column: text;&quot;&gt;

&lt;div style=&quot;display: inline; float: left; width: 45%; text-align: center&quot;&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; max-width: 100%; margin-top: 3rem; margin-bottom: 1rem; margin-left: auto; margin-right: auto&quot; alt=&quot;AI-enabled Exploration and Surveillance&quot; src=&quot;https://tsairesearch.github.io/assets/images/autonomous/mout3_textured.jpg&quot; /&gt;
&lt;figcaption&gt;
A close-up of the patio area with complex geometries such as columns and tree trunks.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;div style=&quot;display: inline; float: right; width: 45%; text-align: center&quot;&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; max-width: 100%; margin-top: 3rem; margin-bottom: 1rem; margin-left: auto; margin-right: auto&quot; alt=&quot;AI-enabled Exploration and Surveillance&quot; src=&quot;https://tsairesearch.github.io/assets/images/autonomous/mout3_recon.jpg&quot; /&gt;
&lt;figcaption&gt;
A coarse reconstruction of the patio generated from the visibility volume.
Despite the low resolution, the topology of the structures are preserved.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;/div&gt;



&lt;div style=&quot;grid-column: text;&quot;&gt;

&lt;div style=&quot;display: inline; float: left; width: 45%; text-align: center&quot;&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; max-width: 100%; margin-top: 3rem; margin-bottom: 1rem; margin-left: auto; margin-right: auto&quot; alt=&quot;AI-enabled Exploration and Surveillance&quot; src=&quot;https://tsairesearch.github.io/assets/images/autonomous/mout2_textured.jpg&quot; /&gt;
&lt;figcaption&gt;
A larger, 50m region around a church with several buildings.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;div style=&quot;display: inline; float: right; width: 45%; text-align: center&quot;&gt;
&lt;figure&gt;
&lt;img style=&quot;display: block; max-width: 100%; margin-top: 3rem; margin-bottom: 1rem; margin-left: auto; margin-right: auto&quot; alt=&quot;AI-enabled Exploration and Surveillance&quot; src=&quot;https://tsairesearch.github.io/assets/images/autonomous/mout2_recon.jpg&quot; /&gt;
&lt;figcaption&gt;
A reconstruction of the building surface using 1,896,786 points generated from 11 vantage locations.
&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;

&lt;/div&gt;




&lt;h3&gt; Publications &lt;/h3&gt;

&lt;p&gt;
&lt;li&gt; L. Ly and R. Tsai. Autonomous exploration, reconstruction, and surveillance of 3D environments aided by deep learning. 2019 International Conference on Robotics and Automation (ICRA). IEEE, 2019.&lt;/li&gt;
&lt;li&gt; M. Hielsberg, R. Tsai, P. Guo, and C. Chen. Visibility-based urban exploration and learning using point clouds. 2013.  &lt;/li&gt;
&lt;li&gt; L. Valente, R. Tsai, and S. Soatto. Information-seeking control under visibility-based uncertainty. Journal of Mathematical Imaging and Vision, 48(2), 339-358, 2014 &lt;/li&gt;
&lt;li&gt; R. Takei, R. Tsai, Z. Zhou, and Y. Landa. An efficient algorithm for a visibility-based surveillance-evasion game. Communications in Mathematical Sciences, Vol (12) No 7, pp.1303-1327, 2014 &lt;/li&gt;
&lt;li&gt; Y. Landa and R. Tsai. Visibility of point clouds and exploratory path planning in unknown environments. Communications in Mathematical Sciences., 6(4), 2008.
&lt;li&gt; C.-Y. Kao and R. Tsai. Properties of a level set algorithm for the visibility problems. Journal of Scientiﬁc Computing, 35(2-3), June 2008.
&lt;li&gt; Y. Landa, D. Galkowski, Y. Huang, A. Joshi, C. Lee, K. Leung, G. Malla, J. Treanor, V. Voroninski, A. Bertozzi, and Y.-H. Tsai. Robotic path planning and visibility with limited sensor data. American Control Conference, 2007. ACC ’07, pages 5425–5430, July 2007.
&lt;li&gt; Y. Landa, R. Tsai, and L. Cheng. Visibility of point clouds and mapping of unknown environments. In Springer Notes in Computational Science and Engineering, pages 1014–1025, 2006.
&lt;li&gt; L.-T. Cheng and Y.-H. Tsai. Visibility optimization using variational approaches. Commun. Math. Sci., 3(3):425–451, 2005
&lt;li&gt; Y.-H. R. Tsai, L.-T. Cheng, S. Osher, P. Burchard, and G. Sapiro. Visibility and its dynamics in a PDE based implicit framework. J. Comput. Phys., 199(1):260–290, 2004.
&lt;li&gt; H. Jin, A. J. Yezzi, Y.-H. Tsai, L.-T. Cheng, and S. Soatto. Estimation of 3D surface shape and smooth radiance from 2D images: a level set approach. J. Sci. Comput., 19(1-3):267–292, 2003. &lt;/li&gt;
&amp;lt;/p&amp;gt;

&lt;h3&gt; Acknowledgements &lt;/h3&gt;
&lt;p&gt;This work is supported by ARO MURI W911NF-07-1-0185 and W911NF-12-1-0519 grants.
&lt;/p&gt;

&amp;lt;/d-article&amp;gt;
&lt;/li&gt;&lt;/li&gt;&lt;/li&gt;&lt;/li&gt;&lt;/li&gt;&lt;/li&gt;&lt;/p&gt;&lt;/d-article&gt;</content><author><name></name></author><category term="projects" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tsairesearch.github.io/assets/images/autonomous/3d.gif" /></entry><entry><title type="html">Point source identification in non-linear advection-diffusion-reaction systems</title><link href="https://tsairesearch.github.io/projects/source" rel="alternate" type="text/html" title="Point source identification in non-linear advection-diffusion-reaction systems" /><published>2012-02-14T00:00:00-06:00</published><updated>2012-02-14T00:00:00-06:00</updated><id>https://tsairesearch.github.io/projects/source</id><content type="html" xml:base="https://tsairesearch.github.io/projects/source">&lt;d-front-matter&gt;
  &lt;script type=&quot;text/json&quot;&gt;{
  &quot;authors&quot;: [
    {
      &quot;author&quot;: &quot;Alexander Mamonov&quot;,
      &quot;authorURL&quot;: &quot;https://www.math.uh.edu/~mamonov/&quot;,
      &quot;affiliation&quot;: &quot;Department of Mathematics, University of Houston&quot;,
      &quot;affiliationURL&quot;: &quot;http://www.uh.edu/&quot;
    },
    {
      &quot;author&quot;: &quot;Yen-Hsi Richard Tsai&quot;,
      &quot;authorURL&quot;: &quot;https://www.ma.utexas.edu/users/ytsai/&quot;,
      &quot;affiliation&quot;: &quot;Oden Institute for Computational Engineering and Sciences, University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.oden.utexas.edu&quot;
    }
  ]
  }&lt;/script&gt;
&lt;/d-front-matter&gt;

&lt;d-title&gt;
 &lt;div style=&quot;grid-column: screen; text-align: center&quot;&gt;
  &lt;h1&gt;Point source identification in non-linear advection-diffusion-reaction systems&lt;/h1&gt;
    
    &lt;img style=&quot;display: block; max-width: 15%; margin-top: 3rem; margin-bottom: 3rem; margin-left: auto; margin-right: auto; border-radius: 5%&quot; alt=&quot;Point source identification in non-linear advection-diffusion-reaction systems&quot; src=&quot;https://tsairesearch.github.io//assets/images/point/fig7.png&quot; /&gt;
    
 &lt;/div&gt;


&lt;/d-title&gt;

&lt;d-article&gt;

&lt;p&gt; We consider a problem of identification of point sources in time dependent advection-diffusion systems with a non-linear reaction term. The linear counterpart of the problem in question can be reduced to solving a system of non-linear algebraic equations via the use of adjoint equations. We extend this approach by constructing an algorithm that solves the problem iteratively to account for the non-linearity of the reaction term. We study the question of improving the quality of source identification by adding more measurements adaptively using the solution obtained previously with a smaller number of measurements. &lt;/p&gt;


&lt;h3&gt; Simulation &lt;/h3&gt;


&lt;div style=&quot;column-grid: middle &quot;&gt;

&lt;figure&gt;
&lt;div style=&quot;display: block; width: 90%; text-align: center&quot;&gt;
&lt;iframe width=&quot;547px&quot; height=&quot;547px&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;true&quot; src=&quot;https://tsairesearch.github.io//assets/images/point/fig7.png&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;figcaption&gt;

&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;/div&gt;


&lt;h3&gt; Publications &lt;/h3&gt;

&lt;p&gt;
&lt;li&gt; A. Mamonov and R. Tsai. Point Source Identification in Non-Linear Advection-Diffusion-Reaction Systems.  Inverse Problems 29, 2013  &lt;/li&gt;
&lt;/p&gt;



&lt;/d-article&gt;</content><author><name></name></author><category term="projects" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tsairesearch.github.io/assets/images/point/fig7.png" /></entry><entry><title type="html">Heat Source Identification Based on L1 Constrained Minimization</title><link href="https://tsairesearch.github.io/projects/heat" rel="alternate" type="text/html" title="Heat Source Identification Based on L1 Constrained Minimization" /><published>2011-01-25T00:00:00-06:00</published><updated>2011-01-25T00:00:00-06:00</updated><id>https://tsairesearch.github.io/projects/heat</id><content type="html" xml:base="https://tsairesearch.github.io/projects/heat">&lt;d-front-matter&gt;
  &lt;script type=&quot;text/json&quot;&gt;{
  &quot;authors&quot;: [
    {
      &quot;author&quot;: &quot;Yingying Li&quot;,
      &quot;authorURL&quot;: &quot;https://math.ucla.edu&quot;,
      &quot;affiliation&quot;: &quot;Department of Mathematics, University of California, Los Angeles&quot;,
      &quot;affiliationURL&quot;: &quot;http://www.math.ucla.edu/&quot;
    },
    {
      &quot;author&quot;: &quot;Stanley Osher&quot;,
      &quot;authorURL&quot;: &quot;https://www.math.ucla.edu/~sjo/&quot;,
      &quot;affiliation&quot;: &quot;Department of Mathematics, University of California, Los Angeles&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.math.ucla.edu&quot;
    },
    {
      &quot;author&quot;: &quot;Yen-Hsi Richard Tsai&quot;,
      &quot;authorURL&quot;: &quot;https://www.ma.utexas.edu/users/ytsai/&quot;,
      &quot;affiliation&quot;: &quot;Oden Institute for Computational Engineering and Sciences, The University of Texas at Austin&quot;,
      &quot;affiliationURL&quot;: &quot;https://www.oden.utexas.edu&quot;
    }
  ]
  }&lt;/script&gt;
&lt;/d-front-matter&gt;

&lt;d-title&gt;
 &lt;div style=&quot;grid-column: screen; text-align: center&quot;&gt;
  &lt;h1&gt;Heat Source Identification Based on L1 Constrained Minimization&lt;/h1&gt;
    
    &lt;img style=&quot;display: block; max-width: 15%; margin-top: 3rem; margin-bottom: 3rem; margin-left: auto; margin-right: auto; border-radius: 5%&quot; alt=&quot;Heat Source Identification Based on L1 Constrained Minimization&quot; src=&quot;https://tsairesearch.github.io//assets/images/heat/heat.png&quot; /&gt;
    
 &lt;/div&gt;


&lt;/d-title&gt;

&lt;d-article&gt;

&lt;p&gt; We consider the inverse problem of finding sparse initial data from the
sparsely sampled solutions of the heat equation. The initial data are assumed
to be a sum of an unknown but finite number of Dirac delta functions at unknown
locations. Point-wise values of the heat solution at only a few locations are
used in an $l_1$ constrained optimization to find the initial data.  A concept
of domain of effective sensing is introduced to speed up the already fast
Bregman iterative algorithm for $l_1$ optimization. Furthermore, an algorithm
which successively adds new measurements at specially chosen locations is
introduced. By comparing the solutions of the inverse problem obtained from
different number of measurements, the algorithm decides where to add new
measurements in order to improve the reconstruction of the sparse initial data.
&lt;/p&gt;

&lt;h3&gt; Simulation &lt;/h3&gt;


&lt;div style=&quot;grid-column: screen &quot;&gt;

&lt;figure&gt;
&lt;div style=&quot;display: block; width: 100%; text-align: center&quot;&gt;
&lt;iframe width=&quot;1050px&quot; height=&quot;827px&quot; frameborder=&quot;0&quot; src=&quot;https://tsairesearch.github.io/assets/images/heat/fig6.png&quot;&gt;&lt;/iframe&gt;

&lt;figcaption&gt;
Recovery of the heat source $u_0$ from 60 randomly selected measurements with 1% noise on a $32 \times 32$ grid.
&lt;/figcaption&gt;
&lt;/div&gt;

&lt;/figure&gt;



&lt;figure&gt;
&lt;div style=&quot;display: block; width: 100%; text-align: center&quot;&gt;
&lt;iframe width=&quot;839px&quot; height=&quot;844px&quot; frameborder=&quot;0&quot; src=&quot;https://tsairesearch.github.io/assets/images/heat/fig7.png&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;figcaption&gt;
&lt;div style=&quot;display: block; margin-right: auto; margin-left: auto; width: 50%; text-align: center&quot;&gt;
Source recovery with a smooth spatially varying thermal conductivity. 
Left: distribution of thermal conductivity (shades of orange);
sampling locations are red stars, heat source locations are blue
dots. Middle: heat distribution at time $T$ (shades of blue). Right:
recovered source.
&lt;/div&gt;
&lt;/figcaption&gt;

&lt;/figure&gt;

&lt;figure&gt;
&lt;div style=&quot;display: block; width: 100%; text-align: center&quot;&gt;
&lt;iframe width=&quot;904px&quot; height=&quot;850px&quot; frameborder=&quot;0&quot; src=&quot;https://tsairesearch.github.io/assets/images/heat/fig10.png&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;figcaption&gt;
&lt;div style=&quot;display: block; margin-right: auto; margin-left: auto; width: 50%; text-align: center&quot;&gt;
Source recovery with successive sampling. The $(k+1)^{th}$ measurement is added in step $k$. The estimate of the source
term is in blue, the exclusion region is in gray, sample locations are
shown as red stars.
&lt;/div&gt;
&lt;/figcaption&gt;



&lt;/figure&gt;








&lt;/div&gt;


&lt;h3&gt; Publications &lt;/h3&gt;

&lt;p&gt;
&lt;li&gt; Y. Li, S. Osher, and R. Tsai. &quot;Heat Source Identification Based Onconstrained Minimization.&quot; Inverse Problems and Imaging 8.1 (2014): 199-221.&lt;/li&gt;
&lt;li&gt; M. Burger,  Y. Landa, N. Tanushev, and R. Tsai. &quot;Discovering a point source in unknown environments.&quot; Algorithmic Foundation of Robotics VIII. Springer, Berlin, Heidelberg, 2009. 663-678.&lt;/li&gt;
&lt;/p&gt;



&lt;/d-article&gt;</content><author><name></name></author><category term="projects" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://tsairesearch.github.io/assets/images/heat/heat.png" /></entry></feed>